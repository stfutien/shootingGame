{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stfutien/shootingGame/blob/master/memo_jupyter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjYy0F2gZIPR",
        "outputId": "ae7d33aa-a303-4ce5-8e18-5b4fe81558a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu124\n",
            "Collecting torch==2.5.1+cu124\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torch-2.5.1%2Bcu124-cp312-cp312-linux_x86_64.whl (908.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.2/908.2 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.20.1+cu124\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torchvision-0.20.1%2Bcu124-cp312-cp312-linux_x86_64.whl (7.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.5.1+cu124\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.5.1%2Bcu124-cp312-cp312-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m96.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchtext==0.18.0\n",
            "  Downloading torchtext-0.18.0-cp312-cp312-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Collecting torchdata==0.8.0\n",
            "  Downloading torchdata-0.8.0-cp312-cp312-manylinux1_x86_64.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1+cu124) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1+cu124) (4.15.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1+cu124) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1+cu124) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1+cu124) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.5.1+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.5.1+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.5.1+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.1+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.4/664.8 MB\u001b[0m \u001b[31m127.4 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install torch==2.5.1+cu124 torchvision==0.20.1+cu124 torchaudio==2.5.1+cu124 torchtext==0.18.0 torchdata==0.8.0 --extra-index-url https://download.pytorch.org/whl/cu124\n",
        "!pip install xformers==0.0.28.post3\n",
        "\n",
        "!pip install accelerate==1.1.1 albumentations==1.4.21 audio-separator==0.24.1 black==23.12.1 diffusers==0.31.0 einops==0.8.0 ffmpeg-python==0.2.0 funasr==1.0.27 huggingface-hub==0.26.2 imageio==2.36.0\n",
        "!pip install imageio-ffmpeg==0.5.1 insightface==0.7.3 hydra-core==1.3.2 jax==0.4.35 mediapipe==0.10.18 modelscope==1.20.1 moviepy==1.0.3 numpy==1.26.4 omegaconf==2.3.0 onnxruntime-gpu==1.20.1\n",
        "!pip install opencv-python-headless==4.10.0.84 pillow==10.4.0 scikit-learn==1.5.2 scipy==1.14.1 transformers==4.46.3 tqdm==4.67.1 matplotlib matplotlib-inline\n",
        "\n",
        "!apt install aria2 ffmpeg -qqy\n",
        "\n",
        "%cd /content\n",
        "!git clone -b dev https://github.com/camenduru/memo\n",
        "%cd /content/memo\n",
        "\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/memoavatar/memo/raw/main/audio_proj/config.json -d /content/memo/checkpoints/audio_proj -o config.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/memoavatar/memo/resolve/main/audio_proj/diffusion_pytorch_model.safetensors -d /content/memo/checkpoints/audio_proj -o diffusion_pytorch_model.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/memoavatar/memo/raw/main/diffusion_net/config.json -d /content/memo/checkpoints/diffusion_net -o config.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/memoavatar/memo/resolve/main/diffusion_net/diffusion_pytorch_model.safetensors -d /content/memo/checkpoints/diffusion_net -o diffusion_pytorch_model.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/memoavatar/memo/raw/main/image_proj/config.json -d /content/memo/checkpoints/image_proj -o config.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/memoavatar/memo/resolve/main/image_proj/diffusion_pytorch_model.safetensors -d /content/memo/checkpoints/image_proj -o diffusion_pytorch_model.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/memoavatar/memo/raw/main/misc/audio_emotion_classifier/config.json -d /content/memo/checkpoints/misc/audio_emotion_classifier -o config.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/memoavatar/memo/resolve/main/misc/audio_emotion_classifier/diffusion_pytorch_model.safetensors -d /content/memo/checkpoints/misc/audio_emotion_classifier -o diffusion_pytorch_model.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/memoavatar/memo/resolve/main/misc/face_analysis/models/1k3d68.onnx -d /content/memo/checkpoints/misc/face_analysis/models -o 1k3d68.onnx\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/memoavatar/memo/resolve/main/misc/face_analysis/models/2d106det.onnx -d /content/memo/checkpoints/misc/face_analysis/models -o 2d106det.onnx\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/memoavatar/memo/resolve/main/misc/face_analysis/models/face_landmarker_v2_with_blendshapes.task -d /content/memo/checkpoints/misc/face_analysis/models -o face_landmarker_v2_with_blendshapes.task\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/memoavatar/memo/resolve/main/misc/face_analysis/models/genderage.onnx -d /content/memo/checkpoints/misc/face_analysis/models -o genderage.onnx\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/memoavatar/memo/resolve/main/misc/face_analysis/models/glintr100.onnx -d /content/memo/checkpoints/misc/face_analysis/models -o glintr100.onnx\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/memoavatar/memo/resolve/main/misc/face_analysis/models/scrfd_10g_bnkps.onnx -d /content/memo/checkpoints/misc/face_analysis/models -o scrfd_10g_bnkps.onnx\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/memoavatar/memo/resolve/main/misc/vocal_separator/Kim_Vocal_2.onnx -d /content/memo/checkpoints/misc/vocal_separator -o Kim_Vocal_2.onnx\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/memoavatar/memo/raw/main/misc/vocal_separator/download_checks.json -d /content/memo/checkpoints/misc/vocal_separator -o download_checks.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/memoavatar/memo/raw/main/misc/vocal_separator/mdx_model_data.json -d /content/memo/checkpoints/misc/vocal_separator -o mdx_model_data.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/memoavatar/memo/raw/main/misc/vocal_separator/vr_model_data.json -d /content/memo/checkpoints/misc/vocal_separator -o vr_model_data.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/memoavatar/memo/raw/main/reference_net/config.json -d /content/memo/checkpoints/reference_net -o config.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/memoavatar/memo/resolve/main/reference_net/diffusion_pytorch_model.safetensors -d /content/memo/checkpoints/reference_net -o diffusion_pytorch_model.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/stabilityai/sd-vae-ft-mse/resolve/main/diffusion_pytorch_model.safetensors -d /content/memo/checkpoints/vae -o diffusion_pytorch_model.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/stabilityai/sd-vae-ft-mse/raw/main/config.json -d /content/memo/checkpoints/vae -o config.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/model.safetensors -d /content/memo/checkpoints/wav2vec2 -o model.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/facebook/wav2vec2-base-960h/raw/main/config.json -d /content/memo/checkpoints/wav2vec2 -o config.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/facebook/wav2vec2-base-960h/raw/main/preprocessor_config.json -d /content/memo/checkpoints/wav2vec2 -o preprocessor_config.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/emotion2vec/emotion2vec_plus_large/resolve/main/model.pt -d /content/memo/checkpoints/emotion2vec_plus_large -o model.pt\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/emotion2vec/emotion2vec_plus_large/raw/main/config.yaml -d /content/memo/checkpoints/emotion2vec_plus_large -o config.yaml\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/emotion2vec/emotion2vec_plus_large/raw/main/configuration.json -d /content/memo/checkpoints/emotion2vec_plus_large -o configuration.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/emotion2vec/emotion2vec_plus_large/raw/main/tokens.txt -d /content/memo/checkpoints/emotion2vec_plus_large -o tokens.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-5BLHe4I4Rp"
      },
      "outputs": [],
      "source": [
        "%cd /content/memo\n",
        "!python inference.py --config configs/inference.yaml --input_image assets/examples/dicaprio.jpg --input_audio assets/examples/speech.wav --output_dir outputs"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}